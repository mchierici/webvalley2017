{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning for the working (biomedical) researcher\n",
    "### Marco Chierici\n",
    "### _Data scientist @ FBK/MPBA_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this handout we will go through basic concepts of machine learning using Scikit-learn and the SEQC neuroblastoma data set [Zhang et al, _Genome Biology_, 2015].\n",
    "\n",
    "In particular, we will focus on a subset of 272 samples (136 training, 136 test), aiming at predicting an extreme disease outcome (favorable vs unfavorable samples: see main paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training set data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_tr = pd.read_csv(\"data/nb_train.txt.gz\", dtype=str, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the data. First, the dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's inside?\n",
    "\n",
    "A peek at the first rows reveals that the first column (the dataframe **index**) contains the sample IDs, the second column is the class (or target), and the remaining columns are genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_tr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the sample IDs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining part of this hands-on, we need the data to be stored in a Numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This keeps the class column as well.\n",
    "\n",
    "But...\n",
    "\n",
    "We need to separate the class from the data, so let's recreate our array by dropping the class column from the original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr.values[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the dtype to float and save the array to x_tr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_tr = data_tr.values[:, 1:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the class column in another Numpy integer array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = data_tr[\"class\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Quick recap\n",
    "\n",
    "- y_tr = 1 indicates **unfavorable** neuroblastoma samples (**bad** outcome)\n",
    "- y_tr = -1 indicates **favorable** neuroblastoma samples (**good** outcome)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract feature and sample names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_tr = data_tr.columns[1:].values.astype(str)\n",
    "samp_tr = data_tr.index.values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the test set data in a Pandas dataframe and create the Numpy arrays for data and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load sol1.py\n",
    "data_ts = pd.read_csv(\"data/nb_test.txt.gz\", dtype=str, sep='\\t', index_col=0)\n",
    "x_ts = data_ts.values[:, 1:].astype(float)\n",
    "y_ts = data_ts[\"class\"].values.astype(int)\n",
    "feat_ts = data_ts.columns[1:].values.astype(str)\n",
    "samp_ts = data_ts.index.values.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_tr = pca.fit_transform(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(z_tr[y_tr == 1, 0], z_tr[y_tr == 1, 1], color=\"r\")\n",
    "plt.scatter(z_tr[y_tr == -1, 0], z_tr[y_tr == -1, 1], color=\"b\")\n",
    "plt.title(\"PCA of Train data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Apply the transformation to the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_ts = pca.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(z_ts[y_ts == 1, 0], z_ts[y_ts == 1, 1], color=\"r\")\n",
    "plt.scatter(z_ts[y_ts == -1, 0], z_ts[y_ts == -1, 1], color=\"b\")\n",
    "plt.title(\"PCA transformation applied to Test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will sort the features according to the Random Forest importances (Gini impurity index), and make a simple stem plot of the first 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(10):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, feat_tr[indices[f]], importances[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.stem(range(10), importances[indices[:10]], align=\"center\")\n",
    "plt.xticks(range(10), feat_tr[indices[:10]], rotation=\"vertical\")\n",
    "plt.xlim([-1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating performance\n",
    "\n",
    "Compute and print the confusion matrix.\n",
    "\n",
    "### Recap\n",
    "\n",
    "In this example, the first row is class -1, so the confusion matrix will look like:\n",
    "\n",
    "|      |  |  Predicted  |    |\n",
    "|------|-----------|----|----|\n",
    "|      |           | -1 | 1  |\n",
    "| True | -1        | TN | FP |\n",
    "|      | 1         | FN | TP |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = confusion_matrix(y_ts, y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of class -1 test samples should be equal to the sum of the first row of the confusion matrix, i.e., TN + FP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_ts==-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for class 1, i.e., FN + TP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_ts==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Accuracy, remembering the formula: \n",
    "\n",
    "ACC = (TN + TP) / (TN + TP + FN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TN and TP are on the main diagonal of our conf Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(conf[0,0] + conf[1,1])/y_ts.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily Scikit-learn provides a quite handy alternative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_ts, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the MCC (again, Scikit-learn comes to our help):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_ts, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple random split of a dataset in two groups (hold-out strategy), leaving 25% of the samples for model evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_tr, y_tr, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "Split the training dataset, x_tr, with a 5-fold partitioning schema, keeping the class label proportions across folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "N = skf.get_n_splits(x_tr, y_tr)\n",
    "\n",
    "for i, (idx_tr, idx_ts) in enumerate(skf.split(x_tr, y_tr)):\n",
    "    print(\"Fold %d / %d\" % (i+1, N))\n",
    "    X_train, Y_train = x_tr[idx_tr], y_tr[idx_tr]\n",
    "    X_test, Y_test = x_tr[idx_ts], y_tr[idx_ts]\n",
    "    print(\"TRAIN size:\", X_train.shape[0])\n",
    "    print(\"-- class 1:\", np.sum(Y_train==1), \"class -1:\", np.sum(Y_train==-1))\n",
    "    print(\"TEST size:\", X_test.shape[0])\n",
    "    print(\"-- class 1:\", np.sum(Y_test==1), \"class -1:\", np.sum(Y_test==-1))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Implementing a basic Data Analysis Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final example, we implement a 10x 5-fold Cross-validation schema with a simple feature ranking. \n",
    "\n",
    "For each CV iteration, a Random Forest model is trained on the training portion of the data, then features are ranked according to the Random Forest importances; a series of Random Forest models are built upon an increasing number of the ranked features (i.e., 1, 5, 10, etc.) and evaluated on the test data in terms of MCC.\n",
    "\n",
    "The average MCC over the 10x5 CV iterations is computed for the different feature set sizes. We choose the feature set size that maximizes the average MCC.\n",
    "\n",
    "This basic example is meant as a starting point for building more complex pipelines, i.e., with more feature steps, (bootstrapped) confidence intervals for MCC, computation of a unified ranked feature list (as in Jurman et al., _Bioinformatics_, 2008)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV_N = 10 # number of CV iterations\n",
    "CV_K = 5 # number of CV folds\n",
    "FEATURE_STEPS = [1, 5, 10, 25, 50, 100]\n",
    "# prepare output MCC array\n",
    "MCC = np.empty((CV_K*CV_N, len(FEATURE_STEPS)))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n in range(CV_N):\n",
    "    print(\"~~~ Iteration %d ~~~\" % (n+1))\n",
    "    skf = StratifiedKFold(n_splits=CV_K, shuffle=True, random_state=n)\n",
    "    for i, (idx_tr, idx_ts) in enumerate(skf.split(x_tr, y_tr)):\n",
    "        print(\"Fold %d\" % (i+1))\n",
    "        X_train, Y_train = x_tr[idx_tr], y_tr[idx_tr]\n",
    "        X_test, Y_test = x_tr[idx_ts], y_tr[idx_ts]\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=500, random_state=n)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        ranking = np.argsort( clf.feature_importances_ )[::-1]\n",
    "        \n",
    "        for j, s in enumerate(FEATURE_STEPS):\n",
    "            v = ranking[:s] # consider the top s ranked features\n",
    "            X_tr_fs, X_ts_fs = X_train[:, v], X_test[:, v] # extract them from internal train and test data\n",
    "            clf.fit(X_tr_fs, Y_train) # train a classifier on the reduced train dataset\n",
    "            YP = clf.predict(X_ts_fs) # predict on the reduced test dataset\n",
    "            MCC[(n*CV_K)+i, j] = matthews_corrcoef(Y_test, YP) # evaluate the model performance\n",
    "        \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(\"MCC_CV\", MCC)\n",
    "MCC = np.load(\"MCC_CV.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MCC_avg = np.mean(MCC, axis=0)\n",
    "MCC_max = np.max(MCC_avg)\n",
    "n_feats = FEATURE_STEPS[np.argmax(MCC_avg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average MCC for each feature step\n",
    "for nf, mcc in zip(FEATURE_STEPS, MCC_avg):\n",
    "    print(\"nf = %d, MCC = %.2f\" % (nf, mcc))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Best MCC = %.2f with %d features\" % (MCC_max, n_feats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Average MCC\")\n",
    "plt.plot(FEATURE_STEPS, MCC_avg, 'o-')\n",
    "plt.xlabel(\"Feature steps\")\n",
    "plt.ylabel(\"MCC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
